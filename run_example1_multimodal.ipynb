{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core.schema import ImageDocument, TextNode\n",
    "from llama_index.multi_modal_llms.openai import OpenAIMultiModal\n",
    "from typing import List\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "FILE_NAME = \"./data/example1/memes.pdf\"\n",
    "IMAGES_DOWNLOAD_PATH = \"./data/example1/images/\"\n",
    "\n",
    "LLAMA_CLOUD_API_KEY = os.environ[\"LLAMA_CLOUD_API_KEY\"]\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 1131bb53-f134-42a4-9c38-84391b24a100\n"
     ]
    }
   ],
   "source": [
    "parser = LlamaParse(\n",
    "    api_key=LLAMA_CLOUD_API_KEY,\n",
    "    result_type=\"markdown\",\n",
    ")\n",
    "\n",
    "json_objs = parser.get_json_result(FILE_NAME)\n",
    "json_list = json_objs[0][\"pages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Image for page 1: [{'name': 'img_p0_1.png', 'height': 371, 'width': 556, 'x': 168.139, 'y': 124.80138916800004, 'original_width': 1599, 'original_height': 1066}]\n"
     ]
    }
   ],
   "source": [
    "def get_text_nodes(json_list: List[dict]) -> List[TextNode]:\n",
    "    return [TextNode(text=page[\"text\"], metadata={\"page\": page[\"page\"]}) for page in json_list]\n",
    "\n",
    "text_nodes = get_text_nodes(json_list)\n",
    "\n",
    "def get_image_nodes(json_objs: List[dict], download_path: str) -> List[ImageDocument]:\n",
    "    image_dicts = parser.get_images(json_objs, download_path=download_path)\n",
    "    return [ImageDocument(image_path=image_dict[\"path\"]) for image_dict in image_dicts]\n",
    "\n",
    "image_documents = get_image_nodes(json_objs, IMAGES_DOWNLOAD_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a cat with a relaxed or indifferent expression, accompanied by the text \"WHEN YOU REALISE IT'S MONDAY.\" This relates to the text you provided by conveying a humorous or relatable sentiment about the feeling of facing a Monday, which is often associated with the end of the weekend and the start of the workweek. The phrase \"Memes can tell more than 1000 words\" suggests that the image effectively communicates this common feeling without needing further explanation.\n"
     ]
    }
   ],
   "source": [
    "openai_mm_llm = OpenAIMultiModal(\n",
    "    model=\"gpt-4o\", api_key=OPENAI_API_KEY, max_new_tokens=300\n",
    ")\n",
    "\n",
    "response = openai_mm_llm.complete(\n",
    "    prompt=f\"How does the image relate to the text: '{text_nodes[0].text}'?\",\n",
    "    image_documents=image_documents,\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
